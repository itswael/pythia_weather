{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6114bf83",
   "metadata": {},
   "source": [
    "# CHIRPS V3 Data Extractor\n",
    "\n",
    "Extract CHIRPS V3.0 precipitation data for specific coordinates and date ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a3e038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Constants\n",
    "LATITUDE = 42.0\n",
    "LONGITUDE = -93.5\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2020-01-31'\n",
    "DATA_DIR = './chirps_v3_data'\n",
    "CHIRPS_V3_BASE_URL = 'https://data.chc.ucsb.edu/products/CHIRPS/v3.0/daily/final/rnl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487512b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "from datetime import datetime\n",
    "from calendar import monthrange\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_existing_files(start_date, end_date, data_dir):\n",
    "    \"\"\"Check which CHIRPS V3 files already exist locally.\"\"\"\n",
    "    start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    existing_files = []\n",
    "    missing_dates = []\n",
    "    \n",
    "    current = start\n",
    "    while current <= end:\n",
    "        year = current.year\n",
    "        month = current.month\n",
    "        day = current.day\n",
    "        \n",
    "        filename = f'chirps-v3.0.rnl.{year}.{month:02d}.{day:02d}.tif'\n",
    "        filepath = Path(data_dir) / filename\n",
    "        \n",
    "        if filepath.exists():\n",
    "            existing_files.append(filepath)\n",
    "        else:\n",
    "            missing_dates.append(current)\n",
    "        \n",
    "        current += pd.Timedelta(days=1)\n",
    "    \n",
    "    total_days = (end - start).days + 1\n",
    "    return {\n",
    "        'existing': existing_files,\n",
    "        'missing': missing_dates,\n",
    "        'total': total_days,\n",
    "        'existing_count': len(existing_files),\n",
    "        'missing_count': len(missing_dates)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457af1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_chirps_v3(missing_dates, data_dir, base_url):\n",
    "    \"\"\"Download missing CHIRPS V3 TIF files.\"\"\"\n",
    "    downloaded = []\n",
    "    failed = []\n",
    "    \n",
    "    for date in missing_dates:\n",
    "        year = date.year\n",
    "        month = date.month\n",
    "        day = date.day\n",
    "        \n",
    "        filename = f'chirps-v3.0.rnl.{year}.{month:02d}.{day:02d}.tif'\n",
    "        filepath = Path(data_dir) / filename\n",
    "        url = f'{base_url}/{year}/{filename}'\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, stream=True, timeout=300)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            \n",
    "            downloaded.append(filepath)\n",
    "            \n",
    "        except Exception as e:\n",
    "            failed.append((filename, str(e)))\n",
    "    \n",
    "    return {'downloaded': downloaded, 'failed': failed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chirps_data(file_paths, lat, lon):\n",
    "    \"\"\"Load CHIRPS V3 data and extract values for specific coordinates.\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for filepath in sorted(file_paths):\n",
    "        filename = filepath.name\n",
    "        parts = filename.split('.')\n",
    "        year = int(parts[3])\n",
    "        month = int(parts[4])\n",
    "        day = int(parts[5])\n",
    "        \n",
    "        da = rioxarray.open_rasterio(filepath, masked=True)\n",
    "        da = da.squeeze().drop_vars('band', errors='ignore')\n",
    "        \n",
    "        point_value = da.sel(x=lon, y=lat, method='nearest').values\n",
    "        \n",
    "        if hasattr(point_value, 'item'):\n",
    "            point_value = point_value.item()\n",
    "        \n",
    "        if point_value < 0 or pd.isna(point_value):\n",
    "            point_value = 0.0\n",
    "        \n",
    "        data.append({\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'day': day,\n",
    "            'precip': float(point_value)\n",
    "        })\n",
    "        \n",
    "        da.close()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef51638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data):\n",
    "    \"\"\"Convert data to DataFrame with DATE (yyyyddd) and CRAIN columns.\"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['DATE'] = df['year'] * 1000 + df['day_of_year']\n",
    "    df['CRAIN'] = df['precip']\n",
    "    \n",
    "    result = df[['DATE', 'CRAIN']].copy()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f18cf",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e5fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_status = check_existing_files(START_DATE, END_DATE, DATA_DIR)\n",
    "file_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5907cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_status['missing_count'] > 0:\n",
    "    download_result = download_chirps_v3(file_status['missing'], DATA_DIR, CHIRPS_V3_BASE_URL)\n",
    "    download_result\n",
    "else:\n",
    "    {'message': 'All files already exist'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed355e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = check_existing_files(START_DATE, END_DATE, DATA_DIR)['existing']\n",
    "raw_data = load_chirps_data(all_files, LATITUDE, LONGITUDE)\n",
    "raw_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6265bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chirps_df = create_dataframe(raw_data)\n",
    "chirps_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
