{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89e49ba",
   "metadata": {},
   "source": [
    "# CHIRPS Data Downloader and Slicer\n",
    "\n",
    "This notebook downloads CHIRPS precipitation data for specific coordinates and date ranges, then extracts the values into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65a0695",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Installation Note for Windows Users\n",
    "\n",
    "**GDAL installation on Windows can be tricky!** Here are your options:\n",
    "\n",
    "### Option 1: Use Conda (Recommended)\n",
    "```bash\n",
    "conda install -c conda-forge gdal\n",
    "```\n",
    "\n",
    "### Option 2: Download Pre-compiled Wheel\n",
    "1. Visit: https://www.lfd.uci.edu/~gohlke/pythonlibs/#gdal\n",
    "2. Download the wheel for your Python version (e.g., `GDAL-3.x.x-cp311-cp311-win_amd64.whl`)\n",
    "3. Install: `pip install path\\to\\GDAL-3.x.x-cp311-cp311-win_amd64.whl`\n",
    "\n",
    "### Option 3: Use Alternative Libraries (Below)\n",
    "We provide an alternative implementation using `xarray` and `rioxarray` that's easier to install on Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ec16b",
   "metadata": {},
   "source": [
    "## Alternative Implementation (Windows-Friendly)\n",
    "\n",
    "This version uses `xarray` instead of GDAL, which is much easier to install on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20ad3f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All packages imported successfully!\n",
      "xarray version: 2025.9.1\n",
      "pandas version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# Alternative imports - Windows-friendly (no GDAL required)\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "print(\"âœ… All packages imported successfully!\")\n",
    "print(f\"xarray version: {xr.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72b79381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative extract function using xarray (no GDAL needed)\n",
    "def extract_chirps_data_xarray(nc_files, lat, lon, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Extract CHIRPS precipitation data using xarray (Windows-friendly, no GDAL)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    nc_files : list\n",
    "        List of NetCDF file paths\n",
    "    lat : float\n",
    "        Latitude of the point\n",
    "    lon : float\n",
    "        Longitude of the point\n",
    "    start_date : datetime\n",
    "        Start date for extraction\n",
    "    end_date : datetime\n",
    "        End date for extraction\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.Series : Time series of precipitation values with dates as index\n",
    "    \"\"\"\n",
    "    nc_files.sort()  # Sort files chronologically\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for nc_file in nc_files:\n",
    "        if not nc_file.endswith('.nc'):\n",
    "            continue\n",
    "        \n",
    "        print(f'Processing {os.path.basename(nc_file)}...')\n",
    "        \n",
    "        try:\n",
    "            # Open NetCDF file with xarray\n",
    "            ds = xr.open_dataset(nc_file)\n",
    "            \n",
    "            # Select nearest point to lat/lon\n",
    "            ds_point = ds.sel(latitude=lat, longitude=lon, method='nearest')\n",
    "            \n",
    "            # Extract precipitation variable (usually 'precip' or 'precipitation')\n",
    "            precip_var = None\n",
    "            for var_name in ['precip', 'precipitation', 'prec', 'rain']:\n",
    "                if var_name in ds_point.data_vars:\n",
    "                    precip_var = var_name\n",
    "                    break\n",
    "            \n",
    "            if precip_var is None:\n",
    "                print(f\"  Warning: Could not find precipitation variable in {nc_file}\")\n",
    "                print(f\"  Available variables: {list(ds_point.data_vars)}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            df_temp = ds_point[precip_var].to_dataframe(name='precip')\n",
    "            \n",
    "            # Filter by date range\n",
    "            df_temp = df_temp[(df_temp.index >= start_date) & (df_temp.index <= end_date)]\n",
    "            \n",
    "            all_data.append(df_temp)\n",
    "            \n",
    "            ds.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {nc_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"âš ï¸ No data extracted!\")\n",
    "        return pd.Series(dtype=float)\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_df = pd.concat(all_data)\n",
    "    \n",
    "    # Convert to Series and handle duplicates\n",
    "    precip_series = combined_df['precip']\n",
    "    \n",
    "    # Remove duplicates (keep first occurrence)\n",
    "    if precip_series.index.duplicated().any():\n",
    "        precip_series = precip_series[~precip_series.index.duplicated(keep='first')]\n",
    "    \n",
    "    # Sort by date\n",
    "    precip_series = precip_series.sort_index()\n",
    "    \n",
    "    # Replace fill values with NaN\n",
    "    precip_series = precip_series.replace(-9999.0, np.nan)\n",
    "    \n",
    "    return precip_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f7c9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_chirps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m     plt.show()\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Plot the data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdf_chirps\u001b[49m) > \u001b[32m0\u001b[39m:\n\u001b[32m     28\u001b[39m     plot_chirps_data(df_chirps, \u001b[33m'\u001b[39m\u001b[33mCHIRPS Daily Precipitation - Ames, Iowa (Jan 2024)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_chirps' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualization function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_chirps_data(df, title='CHIRPS Precipitation Data'):\n",
    "    \"\"\"\n",
    "    Plot CHIRPS precipitation time series\n",
    "    \"\"\"\n",
    "    if len(df) == 0:\n",
    "        print(\"No data to plot!\")\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    for column in df.columns:\n",
    "        ax.plot(df.index, df[column], marker='o', markersize=4, label=column, linewidth=1.5)\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Precipitation (mm)', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ… Visualization function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a single location - Ames, Iowa (your project location)\n",
    "coordinates_test = [\n",
    "    {'id': 'Ames_IA', 'lat': 42.0, 'lon': -93.5}\n",
    "]\n",
    "\n",
    "# Get data for January 2024\n",
    "start = '2024-01-01'\n",
    "end = '2024-01-31'\n",
    "\n",
    "print(\"ðŸ§ª Testing CHIRPS data extraction (xarray version, no GDAL needed)...\\n\")\n",
    "df_chirps = get_chirps_dataframe_xarray(coordinates_test, start, end)\n",
    "\n",
    "if len(df_chirps) > 0:\n",
    "    print(\"\\nðŸ“Š Sample data:\")\n",
    "    print(df_chirps.head(10))\n",
    "    print(\"\\nðŸ“ˆ Statistics:\")\n",
    "    print(df_chirps.describe())\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No data retrieved. Check download status above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7a2f8",
   "metadata": {},
   "source": [
    "## ðŸš€ Test the Alternative Implementation\n",
    "\n",
    "Let's test the xarray-based functions with a sample location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function using xarray\n",
    "def get_chirps_dataframe_xarray(coordinates, start_date, end_date, data_dir='./chirps_data'):\n",
    "    \"\"\"\n",
    "    Download and extract CHIRPS data using xarray (Windows-friendly, no GDAL)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    coordinates : list of tuples or dict\n",
    "        List of (lat, lon) tuples or dict with 'lat' and 'lon' keys\n",
    "        Example: [(28.5, -81.5), (29.0, -82.0)]\n",
    "        Or: [{'id': 'Point1', 'lat': 28.5, 'lon': -81.5}]\n",
    "    start_date : str or datetime\n",
    "        Start date (format: 'YYYY-MM-DD' or datetime object)\n",
    "    end_date : str or datetime\n",
    "        End date (format: 'YYYY-MM-DD' or datetime object)\n",
    "    data_dir : str\n",
    "        Base directory for storing downloaded files\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame : DataFrame with dates as index and locations as columns\n",
    "                      (precipitation values in mm)\n",
    "    \"\"\"\n",
    "    # Convert dates to datetime objects if needed\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    print(f\"Fetching CHIRPS data from {start_date.date()} to {end_date.date()}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Download corrected data\n",
    "    print(\"\\nðŸ“¥ Downloading CHIRPS corrected data...\")\n",
    "    corrected_dir = os.path.join(data_dir, 'corrected')\n",
    "    corrected_files = download_chirps_corrected(start_date, end_date, corrected_dir)\n",
    "    \n",
    "    # For simplicity, we'll just use corrected data for now\n",
    "    # You can add preliminary data logic if needed\n",
    "    all_files = corrected_files\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"âŒ No data files available!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Extract data for each coordinate\n",
    "    print(\"\\nðŸ” Extracting precipitation data for coordinates...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df_dict = {}\n",
    "    \n",
    "    for idx, coord in enumerate(coordinates):\n",
    "        # Parse coordinate\n",
    "        if isinstance(coord, dict):\n",
    "            lat = coord['lat']\n",
    "            lon = coord['lon']\n",
    "            coord_id = coord.get('id', f'Point_{idx+1}')\n",
    "        else:\n",
    "            lat, lon = coord\n",
    "            coord_id = f'Point_{idx+1}'\n",
    "        \n",
    "        print(f\"\\nProcessing {coord_id}: Lat={lat}, Lon={lon}\")\n",
    "        \n",
    "        # Extract data using xarray\n",
    "        precip_series = extract_chirps_data_xarray(all_files, lat, lon, start_date, end_date)\n",
    "        \n",
    "        df_dict[coord_id] = precip_series\n",
    "        print(f\"  âœ“ Extracted {len(precip_series)} days of data\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"âœ… Complete! DataFrame shape: {df.shape}\")\n",
    "    if len(df) > 0:\n",
    "        print(f\"   Date range: {df.index[0].date()} to {df.index[-1].date()}\")\n",
    "    print(f\"   Locations: {len(df.columns)}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dace1354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download functions (same as before, no GDAL dependency)\n",
    "def download_chirps_corrected(start_date, end_date, output_dir='./chirps_data/corrected'):\n",
    "    \"\"\"\n",
    "    Download corrected CHIRPS data (monthly basis)\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    s = requests.Session()\n",
    "    s.mount(\"https://data.chc.ucsb.edu\", requests.adapters.HTTPAdapter(max_retries=10))\n",
    "    \n",
    "    diff_month = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)\n",
    "    downloaded_files = []\n",
    "    \n",
    "    for n in range(diff_month + 1):\n",
    "        yymm = start_date + relativedelta(months=+n)\n",
    "        yy = yymm.strftime(\"%Y\")\n",
    "        mm = yymm.strftime(\"%m\")\n",
    "        \n",
    "        filename = f'chirps-v2.0.{yy}.{mm}.days_p05.nc'\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            print(f'{filename} already exists. Skipping download.')\n",
    "            downloaded_files.append(filepath)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            url = f'https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_daily/netcdf/p05/by_month/{filename}'\n",
    "            print(f'Downloading {filename}...')\n",
    "            response = s.get(url, timeout=80)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f'{filename} downloaded successfully.')\n",
    "            downloaded_files.append(filepath)\n",
    "            \n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f'Failed to download {filename}: {err}')\n",
    "        finally:\n",
    "            if 'response' in locals():\n",
    "                response.close()\n",
    "    \n",
    "    return downloaded_files\n",
    "\n",
    "\n",
    "def download_chirps_preliminary(start_date, end_date, output_dir='./chirps_data/preliminary'):\n",
    "    \"\"\"\n",
    "    Download preliminary CHIRPS data (yearly basis)\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    s = requests.Session()\n",
    "    s.mount(\"https://data.chc.ucsb.edu\", requests.adapters.HTTPAdapter(max_retries=10))\n",
    "    \n",
    "    downloaded_files = []\n",
    "    \n",
    "    for year in range(start_date.year, end_date.year + 1):\n",
    "        filename = f'chirps-v2.0.{year}.days_p05.nc'\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            print(f'{filename} already exists. Skipping download.')\n",
    "            downloaded_files.append(filepath)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            url = f'https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/fixed/netcdf/{filename}'\n",
    "            print(f'Downloading {filename}...')\n",
    "            response = s.get(url, timeout=80)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f'{filename} downloaded successfully.')\n",
    "            downloaded_files.append(filepath)\n",
    "            \n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f'Failed to download {filename}: {err}')\n",
    "        finally:\n",
    "            if 'response' in locals():\n",
    "                response.close()\n",
    "    \n",
    "    return downloaded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13789cba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'osgeo'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdateutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrelativedelta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m relativedelta\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mosgeo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gdal\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mosgeo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgdalconst\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GA_ReadOnly\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Register GDAL drivers\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'osgeo'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from osgeo import gdal\n",
    "from osgeo.gdalconst import GA_ReadOnly\n",
    "\n",
    "# Register GDAL drivers\n",
    "gdal.AllRegister()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127be917",
   "metadata": {},
   "source": [
    "## Step 1: Download CHIRPS NetCDF Files\n",
    "\n",
    "Download corrected and preliminary CHIRPS data for the specified date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6db35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_chirps_corrected(start_date, end_date, output_dir='./chirps_data/corrected'):\n",
    "    \"\"\"\n",
    "    Download corrected CHIRPS data (monthly basis)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    start_date : datetime\n",
    "        Start date for data download\n",
    "    end_date : datetime\n",
    "        End date for data download\n",
    "    output_dir : str\n",
    "        Directory to save downloaded NetCDF files\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : List of downloaded file paths\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    s = requests.Session()\n",
    "    s.mount(\"https://data.chc.ucsb.edu\", requests.adapters.HTTPAdapter(max_retries=10))\n",
    "    \n",
    "    diff_month = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)\n",
    "    downloaded_files = []\n",
    "    \n",
    "    for n in range(diff_month + 1):\n",
    "        yymm = start_date + relativedelta(months=+n)\n",
    "        yy = yymm.strftime(\"%Y\")\n",
    "        mm = yymm.strftime(\"%m\")\n",
    "        \n",
    "        filename = f'chirps-v2.0.{yy}.{mm}.days_p05.nc'\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # Skip if file already exists\n",
    "        if os.path.exists(filepath):\n",
    "            print(f'{filename} already exists. Skipping download.')\n",
    "            downloaded_files.append(filepath)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            url = f'https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_daily/netcdf/p05/by_month/{filename}'\n",
    "            print(f'Downloading {filename}...')\n",
    "            response = s.get(url, timeout=80)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f'{filename} downloaded successfully.')\n",
    "            downloaded_files.append(filepath)\n",
    "            \n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f'Failed to download {filename}: {err}')\n",
    "        finally:\n",
    "            if 'response' in locals():\n",
    "                response.close()\n",
    "    \n",
    "    return downloaded_files\n",
    "\n",
    "\n",
    "def download_chirps_preliminary(start_date, end_date, output_dir='./chirps_data/preliminary'):\n",
    "    \"\"\"\n",
    "    Download preliminary CHIRPS data (yearly basis)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    start_date : datetime\n",
    "        Start date for data download\n",
    "    end_date : datetime\n",
    "        End date for data download\n",
    "    output_dir : str\n",
    "        Directory to save downloaded NetCDF files\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : List of downloaded file paths\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    s = requests.Session()\n",
    "    s.mount(\"https://data.chc.ucsb.edu\", requests.adapters.HTTPAdapter(max_retries=10))\n",
    "    \n",
    "    downloaded_files = []\n",
    "    \n",
    "    for year in range(start_date.year, end_date.year + 1):\n",
    "        filename = f'chirps-v2.0.{year}.days_p05.nc'\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # Skip if file already exists\n",
    "        if os.path.exists(filepath):\n",
    "            print(f'{filename} already exists. Skipping download.')\n",
    "            downloaded_files.append(filepath)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            url = f'https://data.chc.ucsb.edu/products/CHIRPS-2.0/prelim/global_daily/fixed/netcdf/{filename}'\n",
    "            print(f'Downloading {filename}...')\n",
    "            response = s.get(url, timeout=80)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f'{filename} downloaded successfully.')\n",
    "            downloaded_files.append(filepath)\n",
    "            \n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f'Failed to download {filename}: {err}')\n",
    "        finally:\n",
    "            if 'response' in locals():\n",
    "                response.close()\n",
    "    \n",
    "    return downloaded_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0476f407",
   "metadata": {},
   "source": [
    "## Step 2: Extract CHIRPS Data at Specific Coordinates\n",
    "\n",
    "Extract precipitation values from NetCDF files for given lat/lon coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24617c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chirps_data(nc_files, lat, lon, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Extract CHIRPS precipitation data for specific coordinates and date range\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    nc_files : list\n",
    "        List of NetCDF file paths\n",
    "    lat : float\n",
    "        Latitude of the point\n",
    "    lon : float\n",
    "        Longitude of the point\n",
    "    start_date : datetime\n",
    "        Start date for extraction\n",
    "    end_date : datetime\n",
    "        End date for extraction\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.Series : Time series of precipitation values with dates as index\n",
    "    \"\"\"\n",
    "    nc_files.sort()  # Sort files chronologically\n",
    "    \n",
    "    precip_data = {}\n",
    "    \n",
    "    for nc_file in nc_files:\n",
    "        if not nc_file.endswith('.nc'):\n",
    "            continue\n",
    "        \n",
    "        print(f'Processing {os.path.basename(nc_file)}...')\n",
    "        \n",
    "        # Open NetCDF file\n",
    "        dataset = gdal.Open(nc_file, GA_ReadOnly)\n",
    "        \n",
    "        if dataset is None:\n",
    "            print(f'Could not open {nc_file}')\n",
    "            continue\n",
    "        \n",
    "        # Get metadata\n",
    "        meta_nc = dataset.GetMetadata()\n",
    "        date_start_str = meta_nc['time#units'][-19:]  # e.g., '1980-1-1 0:0:0'\n",
    "        datetime_origin = datetime.strptime(date_start_str, '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Get band time values\n",
    "        bands_time_str = meta_nc['NETCDF_DIM_time_VALUES'][1:-1]\n",
    "        bands_time = list(map(int, bands_time_str.split(',')))\n",
    "        \n",
    "        # Get geotransformation\n",
    "        gt = dataset.GetGeoTransform()\n",
    "        \n",
    "        # Convert lat/lon to pixel coordinates\n",
    "        px = int((lon - gt[0]) / gt[1])\n",
    "        py = int((lat - gt[3]) / gt[5])\n",
    "        \n",
    "        # Get number of bands\n",
    "        num_bands = dataset.RasterCount\n",
    "        \n",
    "        # Extract data from each band\n",
    "        for i in range(1, num_bands + 1):\n",
    "            # Calculate date for this band\n",
    "            band_date = datetime_origin + timedelta(days=bands_time[i - 1])\n",
    "            \n",
    "            # Check if date is within requested range\n",
    "            if band_date < start_date or band_date > end_date:\n",
    "                continue\n",
    "            \n",
    "            # Read precipitation value at the pixel\n",
    "            band = dataset.GetRasterBand(i)\n",
    "            data = band.ReadAsArray(px, py, 1, 1)\n",
    "            \n",
    "            if data is None:\n",
    "                precip_value = np.nan\n",
    "            else:\n",
    "                precip_value = data[0][0]\n",
    "                if precip_value == -9999.0:\n",
    "                    precip_value = np.nan\n",
    "            \n",
    "            # Store with date as key\n",
    "            date_str = band_date.strftime('%Y-%m-%d')\n",
    "            precip_data[date_str] = precip_value\n",
    "        \n",
    "        dataset = None  # Close dataset\n",
    "    \n",
    "    # Convert to pandas Series\n",
    "    precip_series = pd.Series(precip_data)\n",
    "    precip_series.index = pd.to_datetime(precip_series.index)\n",
    "    precip_series = precip_series.sort_index()\n",
    "    \n",
    "    return precip_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7627b",
   "metadata": {},
   "source": [
    "## Step 3: Main Function - Get CHIRPS Data for Multiple Coordinates\n",
    "\n",
    "Process multiple coordinates and return a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chirps_dataframe(coordinates, start_date, end_date, data_dir='./chirps_data'):\n",
    "    \"\"\"\n",
    "    Download and extract CHIRPS data for multiple coordinates\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    coordinates : list of tuples or dict\n",
    "        List of (lat, lon) tuples or dict with 'lat' and 'lon' keys\n",
    "        Example: [(28.5, -81.5), (29.0, -82.0)]\n",
    "        Or: [{'id': 'Point1', 'lat': 28.5, 'lon': -81.5}]\n",
    "    start_date : str or datetime\n",
    "        Start date (format: 'YYYY-MM-DD' or datetime object)\n",
    "    end_date : str or datetime\n",
    "        End date (format: 'YYYY-MM-DD' or datetime object)\n",
    "    data_dir : str\n",
    "        Base directory for storing downloaded files\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame : DataFrame with dates as index and locations as columns\n",
    "                      (precipitation values in mm)\n",
    "    \"\"\"\n",
    "    # Convert dates to datetime objects if needed\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    print(f\"Fetching CHIRPS data from {start_date.date()} to {end_date.date()}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Download corrected data\n",
    "    print(\"\\nðŸ“¥ Downloading CHIRPS corrected data...\")\n",
    "    corrected_dir = os.path.join(data_dir, 'corrected')\n",
    "    corrected_files = download_chirps_corrected(start_date, end_date, corrected_dir)\n",
    "    \n",
    "    # Determine if we need preliminary data\n",
    "    # Check the last available date in corrected data\n",
    "    if corrected_files:\n",
    "        last_corrected_file = corrected_files[-1]\n",
    "        dataset = gdal.Open(last_corrected_file, GA_ReadOnly)\n",
    "        if dataset:\n",
    "            meta_nc = dataset.GetMetadata()\n",
    "            date_start_str = meta_nc['time#units'][-19:]\n",
    "            datetime_origin = datetime.strptime(date_start_str, '%Y-%m-%d %H:%M:%S')\n",
    "            bands_time_str = meta_nc['NETCDF_DIM_time_VALUES'][1:-1]\n",
    "            bands_time = list(map(int, bands_time_str.split(',')))\n",
    "            last_corrected_date = datetime_origin + timedelta(days=bands_time[-1])\n",
    "            dataset = None\n",
    "            \n",
    "            print(f\"Last date in corrected data: {last_corrected_date.date()}\")\n",
    "            \n",
    "            # If end_date is after last corrected date, download preliminary data\n",
    "            if end_date > last_corrected_date:\n",
    "                print(\"\\nðŸ“¥ Downloading CHIRPS preliminary data...\")\n",
    "                preliminary_dir = os.path.join(data_dir, 'preliminary')\n",
    "                preliminary_files = download_chirps_preliminary(\n",
    "                    last_corrected_date + timedelta(days=1), \n",
    "                    end_date, \n",
    "                    preliminary_dir\n",
    "                )\n",
    "                all_files = corrected_files + preliminary_files\n",
    "            else:\n",
    "                all_files = corrected_files\n",
    "        else:\n",
    "            all_files = corrected_files\n",
    "    else:\n",
    "        all_files = []\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"âŒ No data files available!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Extract data for each coordinate\n",
    "    print(\"\\nðŸ” Extracting precipitation data for coordinates...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df_dict = {}\n",
    "    \n",
    "    for idx, coord in enumerate(coordinates):\n",
    "        # Parse coordinate\n",
    "        if isinstance(coord, dict):\n",
    "            lat = coord['lat']\n",
    "            lon = coord['lon']\n",
    "            coord_id = coord.get('id', f'Point_{idx+1}')\n",
    "        else:\n",
    "            lat, lon = coord\n",
    "            coord_id = f'Point_{idx+1}'\n",
    "        \n",
    "        print(f\"\\nProcessing {coord_id}: Lat={lat}, Lon={lon}\")\n",
    "        \n",
    "        # Extract data\n",
    "        precip_series = extract_chirps_data(all_files, lat, lon, start_date, end_date)\n",
    "        \n",
    "        df_dict[coord_id] = precip_series\n",
    "        print(f\"  âœ“ Extracted {len(precip_series)} days of data\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"âœ… Complete! DataFrame shape: {df.shape}\")\n",
    "    print(f\"   Date range: {df.index[0].date()} to {df.index[-1].date()}\")\n",
    "    print(f\"   Locations: {len(df.columns)}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f11b6",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Let's test the functions with sample coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de092ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Single coordinate as tuple\n",
    "coordinates_example1 = [\n",
    "    (28.5384, -81.3789),  # Orlando, FL\n",
    "]\n",
    "\n",
    "# Example 2: Multiple coordinates with IDs\n",
    "coordinates_example2 = [\n",
    "    {'id': 'Orlando_FL', 'lat': 28.5384, 'lon': -81.3789},\n",
    "    {'id': 'Gainesville_FL', 'lat': 29.6516, 'lon': -82.3248},\n",
    "    {'id': 'Miami_FL', 'lat': 25.7617, 'lon': -80.1918},\n",
    "]\n",
    "\n",
    "# Define date range\n",
    "start = '2024-01-01'\n",
    "end = '2024-01-31'\n",
    "\n",
    "# Uncomment to run:\n",
    "# df_chirps = get_chirps_dataframe(coordinates_example2, start, end)\n",
    "# print(df_chirps.head())\n",
    "# print(df_chirps.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dcfc3d",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Plot the precipitation time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7088923",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_chirps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m     plt.show()\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Uncomment to plot:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m plot_chirps_data(\u001b[43mdf_chirps\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_chirps' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_chirps_data(df, title='CHIRPS Precipitation Data'):\n",
    "    \"\"\"\n",
    "    Plot CHIRPS precipitation time series\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with dates as index and locations as columns\n",
    "    title : str\n",
    "        Plot title\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    for column in df.columns:\n",
    "        ax.plot(df.index, df[column], marker='o', markersize=3, label=column, linewidth=1.5)\n",
    "    \n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Precipitation (mm)', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to plot:\n",
    "plot_chirps_data(df_chirps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
