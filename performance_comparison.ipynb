{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37dc697",
   "metadata": {},
   "source": [
    "# CHIRPS V3 Download Performance Comparison\n",
    "\n",
    "Comparing sequential vs multithreaded download performance for CHIRPS V3 data (366 daily files for year 2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03747f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHIRPS_V3_BASE_URL = 'https://data.chc.ucsb.edu/products/CHIRPS/v3.0/daily/final/rnl'\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2020-12-31'\n",
    "DATA_DIR_SEQUENTIAL = './chirps_v3_sequential'\n",
    "DATA_DIR_MULTITHREADED = './chirps_v3_multithreaded'\n",
    "MAX_WORKERS = 10  # Number of concurrent download threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date_list(start_date, end_date):\n",
    "    \"\"\"Generate list of dates for download.\"\"\"\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "    \n",
    "    dates = []\n",
    "    current = start\n",
    "    while current <= end:\n",
    "        dates.append(current)\n",
    "        current += pd.Timedelta(days=1)\n",
    "    \n",
    "    return dates\n",
    "\n",
    "# Generate full year date list\n",
    "all_dates = generate_date_list(START_DATE, END_DATE)\n",
    "print(f\"Total files to download: {len(all_dates)}\")\n",
    "print(f\"Date range: {all_dates[0].date()} to {all_dates[-1].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737dceb1",
   "metadata": {},
   "source": [
    "## Method 1: Sequential Download (One by One)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0105652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_sequential(date, data_dir, base_url):\n",
    "    \"\"\"Download a single CHIRPS V3 file.\"\"\"\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    \n",
    "    filename = f'chirps-v3.0.rnl.{year}.{month:02d}.{day:02d}.tif'\n",
    "    filepath = Path(data_dir) / filename\n",
    "    url = f'{base_url}/{year}/{filename}'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, stream=True, timeout=300)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        \n",
    "        return True, filename\n",
    "    except Exception as e:\n",
    "        return False, f\"{filename}: {str(e)}\"\n",
    "\n",
    "def download_all_sequential(dates, data_dir, base_url):\n",
    "    \"\"\"Download all files sequentially.\"\"\"\n",
    "    Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    downloaded = []\n",
    "    failed = []\n",
    "    \n",
    "    for i, date in enumerate(dates, 1):\n",
    "        success, result = download_file_sequential(date, data_dir, base_url)\n",
    "        \n",
    "        if success:\n",
    "            downloaded.append(result)\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Downloaded {i}/{len(dates)} files...\")\n",
    "        else:\n",
    "            failed.append(result)\n",
    "    \n",
    "    return {'downloaded': len(downloaded), 'failed': len(failed), 'failed_files': failed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aebe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean directory if exists\n",
    "if Path(DATA_DIR_SEQUENTIAL).exists():\n",
    "    shutil.rmtree(DATA_DIR_SEQUENTIAL)\n",
    "\n",
    "print(\"Starting Sequential Download...\")\n",
    "print(f\"Downloading {len(all_dates)} files one by one...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result_sequential = download_all_sequential(all_dates, DATA_DIR_SEQUENTIAL, CHIRPS_V3_BASE_URL)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sequential Download Complete!\")\n",
    "print(f\"Downloaded: {result_sequential['downloaded']} files\")\n",
    "print(f\"Failed: {result_sequential['failed']} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f356dff6",
   "metadata": {},
   "source": [
    "## Method 2: Multithreaded Download (Concurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_threaded(date, data_dir, base_url):\n",
    "    \"\"\"Download a single file (thread-safe version).\"\"\"\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    \n",
    "    filename = f'chirps-v3.0.rnl.{year}.{month:02d}.{day:02d}.tif'\n",
    "    filepath = Path(data_dir) / filename\n",
    "    url = f'{base_url}/{year}/{filename}'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, stream=True, timeout=300)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        \n",
    "        return True, filename\n",
    "    except Exception as e:\n",
    "        return False, f\"{filename}: {str(e)}\"\n",
    "\n",
    "def download_all_multithreaded(dates, data_dir, base_url, max_workers=10):\n",
    "    \"\"\"Download all files using multithreading.\"\"\"\n",
    "    Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    downloaded = []\n",
    "    failed = []\n",
    "    completed = 0\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all download tasks\n",
    "        future_to_date = {\n",
    "            executor.submit(download_file_threaded, date, data_dir, base_url): date \n",
    "            for date in dates\n",
    "        }\n",
    "        \n",
    "        # Process completed downloads\n",
    "        for future in as_completed(future_to_date):\n",
    "            completed += 1\n",
    "            success, result = future.result()\n",
    "            \n",
    "            if success:\n",
    "                downloaded.append(result)\n",
    "            else:\n",
    "                failed.append(result)\n",
    "            \n",
    "            if completed % 50 == 0:\n",
    "                print(f\"Downloaded {completed}/{len(dates)} files...\")\n",
    "    \n",
    "    return {'downloaded': len(downloaded), 'failed': len(failed), 'failed_files': failed}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
