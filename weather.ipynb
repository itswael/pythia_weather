{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6fa8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import s3fs\n",
    "from datetime import date, datetime\n",
    "from typing import Any, Dict, Iterable, List, Optional\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5be5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "NASA_POWER_BASE = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "\n",
    "# Known daily Zarr roots (LST) for POWER ARD on AWS S3 (public/anonymous)\n",
    "SYN1DAILY_ZARR_HINT = (\n",
    "    \"https://nasa-power.s3.us-west-2.amazonaws.com/\"\n",
    "    \"syn1deg/temporal/power_syn1deg_daily_temporal_lst.zarr\"\n",
    ")\n",
    "MERRA2DAILY_ZARR_HINT = (\n",
    "    \"https://nasa-power.s3.us-west-2.amazonaws.com/\"\n",
    "    \"merra2/temporal/power_merra2_daily_temporal_lst.zarr\"\n",
    ")\n",
    "\n",
    "# Default variable sets\n",
    "SOLAR_VARS = [\"ALLSKY_SFC_SW_DWN\"]  # SRAD source (W m^-2) -> convert to MJ m^-2 d^-1\n",
    "MET_VARS = [\"T2M\", \"T2M_MAX\", \"T2M_MIN\", \"PRECTOTCORR\", \"T2MDEW\", \"WS2M\", \"RH2M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328d55bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "\n",
    "#find the daily LST zarr under a given prefix\n",
    "def _discover_daily_zarr(prefix: str) -> str:\n",
    "    \"\"\"Discover a DAILY temporal LST Zarr under a given POWER product prefix.\n",
    "    prefix examples: \"nasa-power/syn1deg/temporal/\" or \"nasa-power/merra2/temporal/\"\n",
    "    Returns an HTTPS URL.\n",
    "    \"\"\"\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    keys = [p for p in fs.ls(prefix) if p.endswith(\".zarr\")]\n",
    "    # Prefer names containing daily + temporal + lst\n",
    "    for k in keys:\n",
    "        low = k.lower()\n",
    "        if (\"daily\" in low) and (\"temporal\" in low) and (\"lst\" in low):\n",
    "            # Strip leading bucket name when forming HTTPS URL\n",
    "            path = k.split(\"nasa-power/\", 1)[1]\n",
    "            return f\"https://nasa-power.s3.us-west-2.amazonaws.com/{path}\"\n",
    "    # Fallback: if nothing matches, raise\n",
    "    raise RuntimeError(f\"No DAILY LST Zarr found under {prefix}\")\n",
    "\n",
    "def _open_power_zarr(zarr_url: str) -> xr.Dataset:\n",
    "    store = fsspec.get_mapper(zarr_url)\n",
    "    return xr.open_zarr(store, consolidated=True)\n",
    "\n",
    "\n",
    "def _slice_point(ds: xr.Dataset,\n",
    "                 latitude: float,\n",
    "                 longitude: float,\n",
    "                 start_date: date,\n",
    "                 end_date: date,\n",
    "                 variables: Iterable[str]) -> xr.Dataset:\n",
    "    avail = [v for v in variables if v in ds.data_vars]\n",
    "    if not avail:\n",
    "        raise KeyError(\"None of the requested variables are present. Available examples: \"\n",
    "                       + \", \".join(list(ds.data_vars)[:25]))\n",
    "    sub = ds[avail].sel(lat=latitude, lon=longitude, method=\"nearest\").sel(\n",
    "        time=slice(datetime.combine(start_date, datetime.min.time()),\n",
    "                   datetime.combine(end_date, datetime.min.time()))\n",
    "    )\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f13c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_power_s3_daily(latitude: float,\n",
    "                             longitude: float,\n",
    "                             start_date: date,\n",
    "                             end_date: date,\n",
    "                             include_srad: bool = True,\n",
    "                             include_met: bool = True,\n",
    "                             syn1_url: Optional[str] = None,\n",
    "                             merra2_url: Optional[str] = None):\n",
    "    \"\"\"Fetch daily data directly from POWER S3/Zarr (ARD), merging solar + meteorology.\n",
    "\n",
    "    - Solar SRAD comes from SYN1deg: ALLSKY_SFC_SW_DWN (W m^-2) -> SRAD = *0.0864 (MJ m^-2 d^-1)\n",
    "    - Meteorology (T2M_MAX, T2M_MIN, PRECTOTCORR, etc.) comes from MERRA-2.\n",
    "\n",
    "    Returns a dict with `records` (list of per-day dictionaries) and metadata.\n",
    "    \"\"\"\n",
    "    # Resolve URLs (try provided first; else discover; else fall back to hints)\n",
    "    def _resolve_syn1() -> str:\n",
    "        if syn1_url:\n",
    "            return syn1_url\n",
    "        try:\n",
    "            return _discover_daily_zarr(\"nasa-power/syn1deg/temporal/\")\n",
    "        except Exception:\n",
    "            return SYN1DAILY_ZARR_HINT\n",
    "\n",
    "    def _resolve_merra2() -> str:\n",
    "        if merra2_url:\n",
    "            return merra2_url\n",
    "        try:\n",
    "            return _discover_daily_zarr(\"nasa-power/merra2/temporal/\")\n",
    "        except Exception:\n",
    "            return MERRA2DAILY_ZARR_HINT\n",
    "\n",
    "    out: Dict[str, Any] = {\n",
    "        \"source\": \"s3-zarr\",\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start\": start_date.isoformat(),\n",
    "        \"end\": end_date.isoformat(),\n",
    "    }\n",
    "    df = None\n",
    "    try:\n",
    "        # Open datasets (in threads to avoid blocking loop)\n",
    "        ds_sol = None\n",
    "        ds_met = None\n",
    "        if include_srad:\n",
    "            url_sol = _resolve_syn1()\n",
    "            ds_sol = await asyncio.to_thread(_open_power_zarr, url_sol)\n",
    "            out[\"syn1_url\"] = url_sol\n",
    "        if include_met:\n",
    "            url_met = _resolve_merra2()\n",
    "            ds_met = await asyncio.to_thread(_open_power_zarr, url_met)\n",
    "            out[\"merra2_url\"] = url_met\n",
    "\n",
    "        # Slice\n",
    "        \n",
    "        if ds_met is not None:\n",
    "            sub_met = await asyncio.to_thread(\n",
    "                _slice_point, ds_met, latitude, longitude, start_date, end_date, MET_VARS\n",
    "            )\n",
    "            df_met = sub_met.to_dataframe().reset_index().rename(\n",
    "                columns={\"T2M_MAX\": \"TMAX\", \"T2M_MIN\": \"TMIN\", \"PRECTOTCORR\": \"RAIN\"}\n",
    "            )\n",
    "            df = df_met\n",
    "        if ds_sol is not None:\n",
    "            sub_sol = await asyncio.to_thread(\n",
    "                _slice_point, ds_sol, latitude, longitude, start_date, end_date, SOLAR_VARS\n",
    "            )\n",
    "            df_sol = sub_sol.to_dataframe().reset_index().rename(\n",
    "                columns={\"ALLSKY_SFC_SW_DWN\": \"SRAD_WM2\"}\n",
    "            )\n",
    "            # Convert W/m^2 (mean power) to MJ/m^2/day\n",
    "            df_sol[\"SRAD\"] = df_sol[\"SRAD_WM2\"].astype(float) * 0.0864\n",
    "            df_sol = df_sol[[\"time\", \"SRAD\"]]\n",
    "            if df is None:\n",
    "                df = df_sol\n",
    "            else:\n",
    "                df = pd.merge(df, df_sol, on=\"time\", how=\"inner\")\n",
    "\n",
    "        if df is None:\n",
    "            return {**out, \"error\": \"No data sources selected: set include_srad and/or include_met.\"}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3578b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = await get_power_s3_daily(\n",
    "        latitude=42.0,\n",
    "        longitude=-93.5,\n",
    "        start_date=date(2020, 1, 1),\n",
    "        end_date=date(2020, 3, 31),\n",
    "        include_srad=True,\n",
    "        include_met=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da55f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = pd.to_datetime(df[\"time\"]).dt.strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55e858dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"date\"] + [c for c in df.columns if c not in (\"time\", \"lat\", \"lon\", \"date\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "543c7cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cols:\n",
    "    if c != \"date\":\n",
    "        try:\n",
    "            df[c] = df[c].astype(float).round(1)\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "190ffc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time   T2M  TMAX  TMIN  RAIN  T2MDEW  WS2M  RH2M   lat    lon  SRAD  \\\n",
      "0  2020-01-01  -1.2   4.9  -7.1   0.4    -2.4   4.1  91.7  42.0 -93.75   4.6   \n",
      "1  2020-01-02   0.3   5.0  -3.6   5.1    -0.5   2.7  94.5  42.0 -93.75   5.6   \n",
      "2  2020-01-03  -1.2   2.2  -3.8   2.3    -2.2   3.3  93.5  42.0 -93.75   2.7   \n",
      "3  2020-01-04  -3.6   0.7  -7.5   0.0    -6.1   3.5  84.8  42.0 -93.75   2.7   \n",
      "4  2020-01-05   0.2   5.0  -3.7   0.0    -2.5   6.0  83.5  42.0 -93.75   7.4   \n",
      "..        ...   ...   ...   ...   ...     ...   ...   ...   ...    ...   ...   \n",
      "86 2020-03-27   7.0   9.3   4.8   2.3     6.0   3.4  92.9  42.0 -93.75   6.6   \n",
      "87 2020-03-28  10.1  20.7   5.2   3.8     7.3   5.1  84.7  42.0 -93.75   5.6   \n",
      "88 2020-03-29   7.1  13.7   1.8   0.7     0.8   7.8  66.7  42.0 -93.75  15.4   \n",
      "89 2020-03-30   7.4  16.7  -2.0   0.0    -0.3   2.1  63.2  42.0 -93.75  23.7   \n",
      "90 2020-03-31   7.2  14.1   1.0   0.0     2.0   2.9  72.9  42.0 -93.75  22.8   \n",
      "\n",
      "        date  \n",
      "0   20200101  \n",
      "1   20200102  \n",
      "2   20200103  \n",
      "3   20200104  \n",
      "4   20200105  \n",
      "..       ...  \n",
      "86  20200327  \n",
      "87  20200328  \n",
      "88  20200329  \n",
      "89  20200330  \n",
      "90  20200331  \n",
      "\n",
      "[91 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
