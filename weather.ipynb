{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6fa8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import s3fs\n",
    "from datetime import date, datetime\n",
    "from typing import Any, Dict, Iterable, List, Optional\n",
    "import asyncio\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f5be5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants\n",
    "\n",
    "NASA_POWER_BASE = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "NASA_POWER_S3_BASE = \"https://nasa-power.s3.us-west-2.amazonaws.com/\"\n",
    "\n",
    "# Known daily Zarr roots (LST) for POWER ARD on AWS S3 (public/anonymous)\n",
    "SYN1DAILY_ZARR_HINT = (\n",
    "    \"https://nasa-power.s3.us-west-2.amazonaws.com/\"\n",
    "    \"syn1deg/temporal/power_syn1deg_daily_temporal_lst.zarr\"\n",
    ")\n",
    "MERRA2DAILY_ZARR_HINT = (\n",
    "    \"https://nasa-power.s3.us-west-2.amazonaws.com/\"\n",
    "    \"merra2/temporal/power_merra2_daily_temporal_lst.zarr\"\n",
    ")\n",
    "\n",
    "# Default variable sets\n",
    "SOLAR_VARS = [\"ALLSKY_SFC_SW_DWN\"]  # SRAD source (W m^-2) -> convert to MJ m^-2 d^-1\n",
    "MET_VARS = [\"T2M\", \"T2M_MAX\", \"T2M_MIN\", \"PRECTOTCORR\", \"T2MDEW\", \"WS2M\", \"RH2M\"]\n",
    "\n",
    "RenameMetVars = {\"T2M_MAX\": \"TMAX\", \"T2M_MIN\": \"TMIN\", \"PRECTOTCORR\": \"RAIN\"}\n",
    "RenameSolarVars = {\"ALLSKY_SFC_SW_DWN\": \"SRAD_WM2\"}\n",
    "variable_map = {\n",
    "        'T2M': 'T2M',    # Average temperature (°C)\n",
    "        'TMAX': 'TMAX',  # Maximum temperature (°C)\n",
    "        'TMIN': 'TMIN',  # Minimum temperature (°C)\n",
    "        'RAIN': 'RAIN',  # Precipitation (mm)\n",
    "        'SRAD': 'SRAD',  # Solar radiation (MJ/m²/day)\n",
    "        'T2MDEW': 'TDEW', # Dew point temperature (°C)\n",
    "        'WS2M': 'WIND',   # Wind speed (m/s)\n",
    "        'RH2M': 'RH2M'    # Relative humidity (%)\n",
    "    }\n",
    "\n",
    "# Output directory\n",
    "DATA_DIR = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "328d55bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "\n",
    "#find the daily LST zarr under a given prefix\n",
    "def _discover_daily_zarr(prefix: str) -> str:\n",
    "    \"\"\"Discover a DAILY temporal LST Zarr under a given POWER product prefix.\n",
    "    prefix examples: \"nasa-power/syn1deg/temporal/\" or \"nasa-power/merra2/temporal/\"\n",
    "    Returns an HTTPS URL.\n",
    "    \"\"\"\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    keys = [p for p in fs.ls(prefix) if p.endswith(\".zarr\")]\n",
    "    # Prefer names containing daily + temporal + lst\n",
    "    for k in keys:\n",
    "        low = k.lower()\n",
    "        if (\"daily\" in low) and (\"temporal\" in low) and (\"lst\" in low):\n",
    "            # Strip leading bucket name when forming HTTPS URL\n",
    "            path = k.split(\"nasa-power/\", 1)[1]\n",
    "            return f\"{NASA_POWER_S3_BASE}{path}\"\n",
    "    # Fallback: if nothing matches, raise\n",
    "    raise RuntimeError(f\"No DAILY LST Zarr found under {prefix}\")\n",
    "\n",
    "def _open_power_zarr(zarr_url: str) -> xr.Dataset:\n",
    "    store = fsspec.get_mapper(zarr_url)\n",
    "    return xr.open_zarr(store, consolidated=True)\n",
    "\n",
    "def _slice_point(ds: xr.Dataset,\n",
    "                 latitude: float,\n",
    "                 longitude: float,\n",
    "                 start_date: date,\n",
    "                 end_date: date,\n",
    "                 variables: Iterable[str]) -> xr.Dataset:\n",
    "    avail = [v for v in variables if v in ds.data_vars]\n",
    "    if not avail:\n",
    "        raise KeyError(\"None of the requested variables are present. Available examples: \"\n",
    "                       + \", \".join(list(ds.data_vars)[:25]))\n",
    "    sub = ds[avail].sel(lat=latitude, lon=longitude, method=\"nearest\").sel(\n",
    "        time=slice(datetime.combine(start_date, datetime.min.time()),\n",
    "                   datetime.combine(end_date, datetime.min.time()))\n",
    "    )\n",
    "    return sub\n",
    "\n",
    "def _transform_values(df: pd.DataFrame, out: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Convert a dataframe to a WTH-like dictionary.\"\"\"\n",
    "    df[\"date\"] = pd.to_datetime(df[\"time\"]).dt.strftime(\"%Y%m%d\")\n",
    "    cols = [\"date\"] + [c for c in df.columns if c not in (\"time\", \"lat\", \"lon\", \"date\")]\n",
    "    for c in cols:\n",
    "        if c != \"date\":\n",
    "            try:\n",
    "                df[c] = df[c].astype(float).round(1)\n",
    "            except Exception:\n",
    "                pass\n",
    "    records = df[cols].to_dict(orient=\"records\")\n",
    "    out[\"records\"] = records\n",
    "    out[\"variables\"] = [c for c in cols if c != \"date\"]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07f13c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_power_s3_daily(latitude: float,\n",
    "                             longitude: float,\n",
    "                             start_date: date,\n",
    "                             end_date: date,\n",
    "                             include_srad: bool = True,\n",
    "                             include_met: bool = True,\n",
    "                             syn1_url: Optional[str] = None,\n",
    "                             merra2_url: Optional[str] = None):\n",
    "    \"\"\"Fetch daily data directly from POWER S3/Zarr (ARD), merging solar + meteorology.\n",
    "\n",
    "    - Solar SRAD comes from SYN1deg: ALLSKY_SFC_SW_DWN (W m^-2) -> SRAD = *0.0864 (MJ m^-2 d^-1)\n",
    "    - Meteorology (T2M_MAX, T2M_MIN, PRECTOTCORR, etc.) comes from MERRA-2.\n",
    "\n",
    "    Returns a dict with `records` (list of per-day dictionaries) and metadata.\n",
    "    \"\"\"\n",
    "    # Resolve URLs (try provided first; else discover; else fall back to hints)\n",
    "    def _resolve_syn1() -> str:\n",
    "        if syn1_url:\n",
    "            return syn1_url\n",
    "        try:\n",
    "            return _discover_daily_zarr(\"nasa-power/syn1deg/temporal/\")\n",
    "        except Exception:\n",
    "            return SYN1DAILY_ZARR_HINT\n",
    "\n",
    "    def _resolve_merra2() -> str:\n",
    "        if merra2_url:\n",
    "            return merra2_url\n",
    "        try:\n",
    "            return _discover_daily_zarr(\"nasa-power/merra2/temporal/\")\n",
    "        except Exception:\n",
    "            return MERRA2DAILY_ZARR_HINT\n",
    "\n",
    "    out: Dict[str, Any] = {\n",
    "        \"source\": \"s3-zarr\",\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start\": start_date.isoformat(),\n",
    "        \"end\": end_date.isoformat(),\n",
    "    }\n",
    "    df = None\n",
    "    ds_sol = None\n",
    "    ds_met = None\n",
    "    try:\n",
    "        # Open datasets (in threads to avoid blocking loop)\n",
    "        \n",
    "        if include_srad:\n",
    "            url_sol = _resolve_syn1()\n",
    "            ds_sol = await asyncio.to_thread(_open_power_zarr, url_sol)\n",
    "            out[\"syn1_url\"] = url_sol\n",
    "        if include_met:\n",
    "            url_met = _resolve_merra2()\n",
    "            ds_met = await asyncio.to_thread(_open_power_zarr, url_met)\n",
    "            out[\"merra2_url\"] = url_met\n",
    "\n",
    "        # Slice\n",
    "        \n",
    "        if ds_met is not None:\n",
    "            sub_met = await asyncio.to_thread(\n",
    "                _slice_point, ds_met, latitude, longitude, start_date, end_date, MET_VARS\n",
    "            )\n",
    "            df_met = sub_met.to_dataframe().reset_index().rename(\n",
    "                columns=RenameMetVars\n",
    "            )\n",
    "            df = df_met\n",
    "        if ds_sol is not None:\n",
    "            sub_sol = await asyncio.to_thread(\n",
    "                _slice_point, ds_sol, latitude, longitude, start_date, end_date, SOLAR_VARS\n",
    "            )\n",
    "            df_sol = sub_sol.to_dataframe().reset_index().rename(\n",
    "                columns=RenameSolarVars\n",
    "            )\n",
    "            # Convert W/m^2 (mean power) to MJ/m^2/day\n",
    "            df_sol[\"SRAD\"] = df_sol[\"SRAD_WM2\"].astype(float) * 0.0864\n",
    "            df_sol = df_sol[[\"time\", \"SRAD\"]]\n",
    "            if df is None:\n",
    "                df = df_sol\n",
    "            else:\n",
    "                df = pd.merge(df, df_sol, on=\"time\", how=\"inner\")\n",
    "\n",
    "        if df is None:\n",
    "            return {**out, \"error\": \"No data sources selected: set include_srad and/or include_met.\"}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df, ds_met, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6ece43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wth_format(data_dict: Dict[str, Any], \n",
    "                         station_name: str = \"S3PWR\",\n",
    "                         elevation: float = 0.0) -> str:\n",
    "    \"\"\"Convert NASA POWER data to ICASA .wth format.\n",
    "    \n",
    "    Args:\n",
    "        data_dict: Dictionary with 'records' key containing daily data\n",
    "        station_name: 4-character station identifier\n",
    "        elevation: Station elevation in meters\n",
    "        \n",
    "    Returns:\n",
    "        String in ICASA .wth format\n",
    "    \"\"\"\n",
    "    if \"error\" in data_dict:\n",
    "        raise ValueError(f\"Cannot convert data with error: {data_dict['error']}\")\n",
    "    \n",
    "    records = data_dict.get(\"records\", [])\n",
    "    if not records:\n",
    "        raise ValueError(\"No data records found\")\n",
    "    \n",
    "    # Extract metadata\n",
    "    latitude = data_dict.get(\"latitude\", 0.0)\n",
    "    longitude = data_dict.get(\"longitude\", 0.0)\n",
    "    \n",
    "    # Build header\n",
    "    wth_lines = []\n",
    "    wth_lines.append(\"@WEATHER DATA : NASA POWER via S3/Zarr\")\n",
    "    wth_lines.append(\"\")\n",
    "    wth_lines.append(\"@ INSI      LAT     LONG  ELEV   TAV   AMP REFHT WNDHT\")\n",
    "    wth_lines.append(f\"  {station_name:>4} {latitude:8.3f} {longitude:8.3f} {elevation:5.0f}  -99.0  -99.0  -99.0  -99.0\")\n",
    "    wth_lines.append(\"\")\n",
    "    \n",
    "    # Determine available variables and create header\n",
    "    sample_record = records[0]\n",
    "\n",
    "    # Find which variables are available\n",
    "    available_vars = []\n",
    "    header_vars = ['DATE']\n",
    "    for nasa_var, icasa_var in variable_map.items():\n",
    "        if nasa_var in sample_record:\n",
    "            available_vars.append((nasa_var, icasa_var))\n",
    "            header_vars.append(icasa_var)\n",
    "    \n",
    "    # Add data header\n",
    "    wth_lines.append(\"@  DATE\" + \"\".join(f\"{var:>8}\" for var in header_vars[1:]))\n",
    "    \n",
    "    # Add data records\n",
    "    for record in records:\n",
    "        date_str = record['date']\n",
    "        # Format: YYYYDDD (4-digit year + day of year)\n",
    "        year = int(date_str[:4])\n",
    "        month = int(date_str[4:6])\n",
    "        day = int(date_str[6:8])\n",
    "        \n",
    "        # Calculate day of year\n",
    "        date_obj = datetime(year, month, day)\n",
    "        day_of_year = date_obj.timetuple().tm_yday\n",
    "        \n",
    "        formatted_date = f\"{year}{day_of_year:03d}\"\n",
    "        \n",
    "        # Build data line\n",
    "        data_line = f\"{formatted_date:>7}\"\n",
    "        for nasa_var, icasa_var in available_vars:\n",
    "            value = record.get(nasa_var, -99.0)\n",
    "            if value is None or pd.isna(value):\n",
    "                value = -99.0\n",
    "            data_line += f\"{value:8.1f}\"\n",
    "        \n",
    "        wth_lines.append(data_line)\n",
    "    \n",
    "    return \"\\n\".join(wth_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74f8328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_wth_data(wth_content: str, \n",
    "                  filepath: Path ) -> str:\n",
    "    \"\"\"Save .wth formatted data.\n",
    "    \n",
    "    Args:\n",
    "        wth_content: ICASA .wth format content\n",
    "        latitude: Latitude coordinate\n",
    "        longitude: Longitude coordinate\n",
    "        start_date: Start date for filename\n",
    "        end_date: End date for filename\n",
    "        data_dir: Directory to save the file\n",
    "        \n",
    "    Returns:\n",
    "        Path to the saved file\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Save data\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(wth_content)\n",
    "    \n",
    "    return str(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61b7ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_Daily_S3_WTH(\n",
    "        latitude=42.0,\n",
    "        longitude=-93.5,\n",
    "        start_date=date(2020, 1, 1),\n",
    "        end_date=date(2020, 3, 31)):\n",
    "\n",
    "    # Fetch data from NASA POWER S3/Zarr\n",
    "    df, ds_met, out = await get_power_s3_daily(\n",
    "            latitude=42.0,\n",
    "            longitude=-93.5,\n",
    "            start_date=date(2020, 1, 1),\n",
    "            end_date=date(2020, 3, 31),\n",
    "            include_srad=True,\n",
    "            include_met=True\n",
    "        )\n",
    "\n",
    "    # fix the data values\n",
    "    data_dict = _transform_values(df, out)\n",
    "\n",
    "    # Convert to ICASA format\n",
    "    icasa_format_data = convert_to_wth_format(data_dict, \"NASA\", 40.0)\n",
    "\n",
    "    # Create data directory if it doesn't exist\n",
    "    Path(DATA_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "    # Generate filename\n",
    "    filename = f\"NP{latitude}_{longitude}_{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}.wth\"\n",
    "    filepath = Path(DATA_DIR) / filename\n",
    "\n",
    "    # Save data\n",
    "    save_wth_data(icasa_format_data, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "14617687",
   "metadata": {},
   "outputs": [],
   "source": [
    "await get_Daily_S3_WTH()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
